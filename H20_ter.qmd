---
title: "H20 ML"
format: html
---

## 

```{r}
#| include: false

# # install.packages("h2o")
# if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
# if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
# 
# pkgs <- c("RCurl","jsonlite")
# for (pkg in pkgs) {
#   if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
# }
# 
# install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/latest_stable_R")))

library(h2o)
localH2O = h2o.init()

```

```{r}
#| message: false
#| warning: false
#| include: false
# H2O works best with 64-bit Java
h2o.init()
# Train <- h2o.importFile("Train.csv")
# h2o.head(Train)
```

```{r}

# train <- data.table::fread("Train.csv")[,-1]
test<- data.table::fread("Test_vars.csv") %>% select(-V1)
 train <- data.table::fread("Train_vars.csv")[,-1]


```

#### Packages

```{r}
#| echo: false
#| message: false
#| warning: false
# install.packages("echarts4r")
library(echarts4r)
library(data.table)


library(dplyr)
library(ggplot2)
library(h2o4gpu)
library(h2otools)
library(cowplot)
library(gridExtra)
library(gt)
# Installer bbplot depuis GitHub
# devtools::install_github("bbc/bbplot")
library(bbplot)
library(ggpubr)
library(glitr)
library(kableExtra)
library(gt)
library(plotly)
colors <- palette.colors(4)
```

```{r}
colors <- c("#000000" ,"#E69F00" ,"#56B4E9" ,"#009E73","#D02090","#CD5555")
```

```{r}
#| message: false
#| warning: false

creditcard <- data.table::fread("creditcard.csv/creditcard.csv")
Vars <-  creditcard %>% dplyr::select( V17,V10,V11,V7,V3,V16,V12, V14,Class,Time,V5,V25)


data <- as.h2o(Vars)

split <- h2o.splitFrame(data,ratios = 0.8,seed = 123)

train <- split[[1]]
test  <- split[[2]]


split_calib <- h2o.splitFrame(data,ratios = c(0.6,0.3),seed=123)
train <- split_calib[[1]]
test  <- split_calib[[2]]
calib <- split_calib[[3]]

# 
train$Class <- as.factor(train$Class)
test$Class <- as.factor(test$Class)
# 

Train_over <- h2o.importFile("Train_over_h20.csv")
Train_both <- h2o.importFile("Train_both_h20.csv")

x <- setdiff(names(train),"Class")
y <- "Class"

Train_over$Class <- as.factor(Train_over$Class)
Train_both$Class <- as.factor(Train_both$Class)
```

```{r}
#| include: false
library(ROSE)
set.seed(123)
Train <- as.data.frame(train)
# Train$Class
Train_over <- ovun.sample(Class~.,Train ,method = "over")$data |>
  as.h2o()
Train_under <- ovun.sample(Class~.,Train,method = "under",p=0.3)$data |> as.h2o()
Train_both <- ovun.sample(Class~.,Train ,method = "both",p=0.3)$data |> as.h2o()
```

```{r}
Train_over$Class <- as.factor(Train_over$Class)
Train_both$Class <- as.factor(Train_both$Class)
```

#### Fonctions

```{r}
#| message: false
#| warning: false

draw_pr <- function(perf,sub,cap,x=0.5,y=moyenne+0.05){
  
pr_data <- data.frame(
  Recall=h2o.recall(perf)[,2],
  Precision=h2o.precision(perf)[,2]
)
moyenne <- mean(pr_data$Precision)
moy_rec <- mean(pr_data$Recall)

p <- pr_data %>% ggplot(aes(x=Recall,y=Precision))+
  geom_line()+
  geom_hline(yintercept = moyenne,color="red",linetype="dashed")+
  annotate("text",x=x,y=y,label="Moyenne de la precision",color="gray30")+
  ggthemes::theme_fivethirtyeight(base_family = "serif")+
  labs(title="Courbe Precision-Recall",
       subtitle = sub,
       caption=cap)+
  geom_ribbon(aes(ymin=0,ymax=Precision),fill="#E69F00",alpha=0.2)
  theme(plot.title.position = "plot",
        plot.caption.position = "plot",
        text=element_text(colour="grey30"))
  
  print(p)
  
}

Lift <- function(model){

lift <- h2o.gains_lift(model) |> 
  select(lift,cumulative_lift,cumulative_gain,cumulative_data_fraction,cumulative_capture_rate)



 A <- lift|> 
  ggplot(aes(x=cumulative_data_fraction))+
  geom_line(aes(y=cumulative_capture_rate),color="#178840",linewidth=1)+
  geom_line(aes(y=cumulative_lift),color=colors[1],linewidth=1)+
   theme(panel.grid = element_blank())+
  si_style_transparent()+
  labs(y="Cumulative capture rate,Cumulative lift",
       x="Fractions des données cumulées ",
       title = "Courbe des gains cumulée et ")+ 
  theme(plot.title.position = "plot",
        plot.title = element_text(family="serif",face = "bold.italic"))
  
  
 B <- lift |> 
  ggplot(aes(x=cumulative_data_fraction))+
  geom_line(aes(y=lift),color=colors[2],linewidth=1)+
  # geom_line(aes(y=cumulative_lift),color=colors[1],linewidth=1)+
   theme(panel.grid = element_blank())+
  si_style_transparent()+
  labs(y="Lift",
       x="Fractions des données cumulées ",
       title = "Courbe Lift")+ 
  theme(plot.title.position = "plot",
        plot.title = element_text(family="serif",face = "bold.italic"))
  

 cowplot::plot_grid(A,B)
}



matrice_conf <- function(performance,Nom_modele,Source){
matrice<- h2o.confusionMatrix(performance)
names(matrice) <- c("Légitime","Fraude","Erreur","Pourcentage")
cbind(" "=c(rep("Predit=",2)," "),"Observé= " =c("Légitime","Fraude","Total"),matrice)%>% gt() %>% tab_header(
  title=paste("Matrice de confusion du modèle ",Nom_modele),
  subtitle = md("0:Pas fraude,1:Fraude")
) %>% opt_align_table_header(
  align = "left"
) %>% fmt_number(columns = Erreur,decimals = 4) %>% cols_width(
    Légitime ~ px(120),
    Fraude ~ px(60),
    Erreur ~ px(120)
    
  ) %>% tab_source_note(
    source_note = md(Source)) %>% 
  tab_footnote(
    footnote = "Faux positive",
    locations = cells_body(columns = Légitime,
                           rows =2)
  ) %>% 
  tab_footnote(
    footnote = "Faux negative",
    locations = cells_body(columns = Fraude,
                            rows = 1))
    
}



# ------------------------------------------------------------------------#
# Courbe Roc                                                              #
# ------------------------------------------------------------------------#


Roc <- function(performance){
roc_data <- data.frame(
  Sensitivite = h2o.tpr(performance)$tpr,
  Specificite = h2o.fpr(performance)$fpr
)

# Tracer la courbe ROC
ggplot(roc_data, aes(x = Specificite, y = Sensitivite)) +
  geom_line(color="black",linewidth=1) +
  labs(x = "1-Specificité", y = "Sensitivité", title = "Courbe ROC")+
  geom_abline(intercept = 0,color="skyblue",linewidth=0.7)+
  si_style()
}



#---------------------------------------------------------------------------#
# PloImportance_permutation
# --------------------------------------------------------------------------#

Importance_plot <- function(model,test,metric="PR_AUC",n_repats=10){
  
Importance_permutation <- h2o.permutation_importance(model,test,seed=123,metric = metric)


A <- h2o.permutation_importance(model,test,seed=123,metric = metric,n_repeats = n_repats)
# 


D <- Importance_permutation |> ggplot(aes(x=reorder(Variable,-`Scaled Importance`),y=`Scaled Importance`,fill=`Scaled Importance`))+
  geom_col()+
  scale_fill_viridis_b(option  = "A")+
  labs(x="Variable",
       y="Valeurs Normalisé",
       fill="Valeurs Normalisé")
  # theme(title = element_text(size = 10))

B <- Importance_permutation |> ggplot(aes(x=reorder(Variable,-Percentage),y=Percentage,fill=Percentage))+
  geom_col()+
  scale_fill_viridis_b(option = "A")+
  labs(x="Variables",
       y="Pourcentage",
       title = "Contributions des variables en %")

# h2o.auc()

# Transformation des données pour ggplot
df_long <- A |> pivot_longer(cols = starts_with("Run"), 
                              names_to = "Run", values_to = "Importance")



# Boxplot avec un remplissage basé sur l'importance
C <- ggplot(df_long, aes(x = reorder(Variable,Importance), y = Importance ,fill=Variable)) +
  geom_boxplot() +
  # geom_jitter()+
  scale_fill_viridis_d(option = "plasma") +
  theme_minimal() +
  labs(title = "Distribution des Importances par Variable",
       x = "",
       y = "Importance") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  coord_flip()+
  # ggthemes::theme_fivethirtyeight()+
  si_style(text_scale = 0.8)+
  theme(legend.position = "right",
        axis.text.y = element_blank(),
        plot.title.position = "plot",
        axis.title.x = element_text(size = 10.5,face = "bold.italic"))

# grid.arrange(A,B,C)
C+( D/B)+
  plot_layout(widths = c(3,2))+
  plot_annotation(
    title = "Importances Variables",
    tag_levels = c("A"),
    tag_prefix = "Figure",
    tag_suffix = ":"
  )

}










#---------------------------------------------------------------------------#
# Performance data
# --------------------------------------------------------------------------#



performance_all_model <- function(model, threshold, Nom) {
  performance <- h2o.performance(model ,test)
  sensitivity = h2o.sensitivity(performance, thresholds = threshold)
  specificity = h2o.specificity(performance, thresholds = threshold)
  F1 = h2o.F1(performance, thresholds = threshold)
  AUC = h2o.auc(performance)
  AUC_pr = h2o.aucpr(performance)
  TPR = h2o.tpr(performance, thresholds = threshold)
  TNR = h2o.tnr(performance,thresholds = threshold)
  Recall = h2o.recall(performance, thresholds = threshold)
  mcc = h2o.mcc(performance,thresholds = threshold)
  mean_per_class_error = h2o.mean_per_class_error(performance)
  erreur = h2o.error(performance,thresholds = threshold)
  missrate = h2o.missrate(performance , thresholds = threshold)
  
  
  # Create a data frame to store the performance metrics
  data <- data.frame(
    row.names = Nom,
    sensitivity = sensitivity,
    AUC = AUC,
    AUC_pr = AUC_pr,
    TPR = TPR,
    TNR = TNR,
    Recall = Recall,
    mcc = mcc,
    mean_per_class_error = mean_per_class_error,
    F1 = F1 ,
    Erreur = erreur ,
    Missrate = missrate )
  # )[1,]
  
  colnames(data) <- c(" sensitivity ",
    "AUC" ,
   " AUC_pr",
    "TPR",
   " TNR ",
  " Recall ",
    "mcc",
   " mean_per_class_error ",
    "F1" ,
    "Erreur",
    "Missrate"
  # )[1,]"
    
  )
  
  return(data )
}




#---------------------------------------------------------------------------#
# Vue d'ensemble 
# --------------------------------------------------------------------------#

View_perf <- function(model,test){
  performance <- h2o.performance(model,test)
  performance@metrics$thresholds_and_metric_scores |> select(threshold,absolute_mcc,tpr,tnr,fpr,fnr,f1,f2,precision,f0point5) |>  View()
}

# Example usage

```

```{r}
rf_model_both <- h2o.randomForest(
  x = x,      # Variables prédictives
  y =y,                 # Variable cible
  training_frame = Train_both,        # Ensemble d'entraînement
  validation_frame = test,       # Ensemble de test
  ntrees = 100,                  # Nombre d'arbres
  max_depth = 8,                # Profondeur max des arbres
  min_rows = 2,                  # Nombre min d’observations par nœud
  seed = 123
)

# Prédictions sur le test set
rf_pred_prob<- h2o.predict(rf_model_both, test)

# Résumé du modèle
rf_perf_both <- h2o.performance(rf_model_both, test)

rf_perf@metrics$thresholds_and_metric_scores %>% select(threshold,tnr,fns,fps,f1,recall,specificity) %>% View()




```

#### Matrices de confusion

```{r}
matric_conf(rf_perf_both,"RF","Methode d'echantillonage:**Oversampling + UnderSampling**")
```

```{r}
rf_pred <- ifelse(rf_pred_prob$p1 > 0.7840127,1,0)
h2o.table(rf_pred,test$Class)
```

##### Courbe Roc

```{r}
# par(mfrow=c(1,3))
plot(rf_perf_both,"roc",main="Courbe Roc",cex.main=0.2)

```

##### Learning Curve

```{r}
 h2o.learning_curve_plot(rf_model,"AUC")+labs(
  title = "Courbe d'apprentissage ",
  subtitle = "Forêt aléatoire(Model)",
  x="Arbres",
  caption = "Les donnés ont étais échantillonné avec la méthode Under et Over Sampling"
) +geom_jitter(shape=21,size=0.5)+
  ggthemes::theme_fivethirtyeight(base_size = 9,
                                   base_family = "serif")+
  theme(text = element_text(
    colour = "grey30"
  ),plot.title.position = "plot",
  plot.caption.position = "plot"
  )
```

#### Courbe precision rappel

```{r}
draw_pr(rf_perf_both,"Modéle : RF","Données échantillonné avec (Over +under Sampling)",x=0.7)
```

#### Diagramme de gain cumulé

```{r}

Lift(rf_model_both)
```

##### Feature importances

```{r}
h2o.varimp_plot(rf_model_both,6)
```

```{r}
# this method plots either a bar plot or if n_repeats > 1 a box plot and returns the variable importance table.
h2o.permutation_importance_plot(rf_model,test,"PR_AUC",seed=123,n_repeats = 10)
```

##### LIME

```{r}

h2o.pd_plot(rf_model,test,"V14")
```

```{r}
rf_model_over <- h2o.randomForest(
  x =x,      # Variables prédictives
  y = y,                 # Variable cible
  training_frame = Train_both,        # Ensemble d'entraînement
  validation_frame = test,       # Ensemble de test
  ntrees = 100,                  # Nombre d'arbres
  max_depth = 8,                # Profondeur max des arbres
  # min_rows = 2,                  # Nombre min d’observations par nœud
  seed = 123  ,
  nfolds = 5
  # nfolds = 5 ,# Reproductibilité
  # class_sampling_factors = c(1,5)
  
)

# Prédictions sur le test set


rf_predictions <- h2o.predict(rf_model_over, test)

# Résumé du modèle
rf_perf_over <- h2o.performance(rf_model_over, test,valid=TRUE)
rf_perf_over
```

#### Matrice de confusion

```{r}
matrice_conf(rf_perf_over,"Random Forest","Methode d'echantillonage: **Oversampling**")
```

##### Courbe d'apprentissage

```{r}
 h2o.learning_curve_plot(rf_model_over,"aucpr")+labs(
  title = "Courbe d'apprentissage ",
  subtitle = "Forêt aléatoire(Model)",
  x="Arbres",
  caption = "Les donnés ont étais échantillonné avec la méthode OverSampling"
) +geom_jitter(shape=21,size=0.5)+
  ggthemes::theme_fivethirtyeight(base_size = 9,
                                   base_family = "serif")+
  theme(text = element_text(
    colour = "grey30"
  ),plot.title.position = "plot",
  plot.caption.position = "plot"
  )
```

##### Cpurbe roc

```{r}

plot(rf_perf_over,type="roc",main="Courbe roc RF : Oversampling",font.main=12,main.col="red")
```

#### Courbe lift

```{r}
Lift(rf_model_over)
```

#### Courbe recall-precision

```{r}

draw_pr(rf_perf_over," ","Données avec un échantillonnage OverSampling",x=0.7)
```

```{r}
# h2o.confusionMatrix(perf) %>% cvms::plot_confusion_matrix()
library(cvms)
```

```{r}
# show(object=rf_model)
```

## Modele Logistique

```{r}

glm_model <- h2o.glm(
  x = x,
  y = y,
  training_frame = Train_both,
  validation_frame = test,
  family = "binomial",
  lambda_search = TRUE , # Recherche de régularisation (LASSO/Ridge)
  # alpha = c(0,1,0.5,0.6,0.4),
  alpha= seq(0,1,length=10),
  seed=123,
  nfolds = 8,
  keep_cross_validation_predictions = TRUE, #
  fold_assignment = "Random"
  
  # stopping_metric = "logloss",
  # stopping_tolerance = 0.001,
  # stopping_rounds = 6
  
  
)


glm_perf_both <- h2o.performance(glm_model)
```

```{r}
matrice_conf(glm_perf_both,"Modèle ::Logistique","Echantillonage:OverSampling")
```

#### *Learning* *Curve pour over*

```{r}
#| message: false
#| warning: false
library(ggthemes)
 h2o.learning_curve_plot(glm_model)+labs(
  title = "Courbe d'apprentissage ",
  subtitle = "Régression logistiques (Model)",
  x="Arbres",
  caption = "Data:Vars OverSampling"
)+geom_jitter(shape=21,size=0.5)+
  # ggthemes::theme_fivethirtyeight(base_size = 9,
  #                                  base_family = "serif")+
   si_style()+
  theme(text = element_text(
    colour = "grey30"
  ),plot.title.position = "plot",
  plot.caption.position = "plot"
  )+scale_color_manual(values=c("#E69F00", "#009E73", "#0072B2","#CC79A7"))+
  guides(fill="none")

```

#### Courbe roc

```{r}
par(bg="#FFFACD")
plot(glm_perf_both,"roc",main="Courbe roc")
grid()

```

##### Courbe precision-rappel

```{r}
draw_pr(glm_perf_both,"Modéle: Regression logistique","Type d'échantillonnage: Over +Under Sampling",x=0.8)
  
```

##### Diagramme des gains cumulé

```{r}
Lift(glm_model)
```

##### Lime

```{r}


explicateur <- lime::lime(x=train_both,model=rf_model_both)

explications <- lime::explain(x = Test, explainer = explainer, n_labels = 1, n_features = 5)


lime::plot_features(explications)
```

#### Gradient Boosting

```{r}
# Définir les hyperparamètres à tester
hyper_params <- list(
  learn_rate = c(0.01, 0.05, 0.1, 0.2, 0.3)
  # max_depth = c(3, 5, 6, 8),
  # ntrees = c(50, 100, 150)
)


# Configuration de la recherche par grille

grid_search = h2o.grid(
  algorithm = "gbm",
  grid_id = "gbm_grid",
  x = x,
  y = y,
  training_frame = Train_over,
  validation_frame = test,
  # nfolds = 5,
  fold_assignment = "Random",
  seed = 123,
  sample_rate = 0.85,
  keep_cross_validation_predictions = TRUE,
  hyper_params = hyper_params
)

# Lancer la recherche par grille
grid_search.train()

# Afficher les résultats triés par performance (par défaut, c'est l'erreur qui est utilisée)
sorted_grid = grid_search.get_grid(sort_by='auc', decreasing=True)
print(sorted_grid)

```

```{r}
auto_both <- h2o.automl(
  x=x,
  y=y,
  training_frame = Train_both,
  validation_frame = test,
  nfolds = 5,
  seed = 123,
  max_models = 50,
  project_name = "TER",
  keep_cross_validation_predictions = TRUE,
  keep_cross_validation_models = TRUE,
  keep_cross_validation_fold_assignment = TRUE,
  exclude_algos = c("DeepLearning"),
sort_metric = "AUCPR",
max_runtime_secs = 3600 
  
)
```

```{r}
# répertoire 
path_save <- "C:/TER2/TER/auto_ml_both_model"

# on recupere les id_des_models
model_ids <- as.vector(auto_both@leaderboard$model_id)

# Sauvegarder chaque modèle
for (i in seq_along(model_ids)) {
  model <- h2o.getModel(model_ids[i])  # Récupérer le modèle
  h2o.saveModel(object = model, path = path_save, force = TRUE)
}

```

```{r}
model_ids <- as.data.frame(auto_both@leaderboard$model_id)
# GBM_model <- h2o.getModel()
# GBM_model_id <- model_ids |>filter(grepl("^GBM",model_id))
best_gbm_model <- h2o.get_best_model(auto_both,"gbm",criterion="AUCPR")
best_glm_model <- h2o.get_best_model(auto_both,"glm",criterion="AUCPR")
best_drf_model <- h2o.get_best_model(auto_both,"drf",criterion ="AUCPR")
best_xrt_model <- h2o.getModel("XRT_1_AutoML_1_20250310_02332")
# best_xrt_model <- h2o.get_best_model(auto_both,"",criterion ="AUCPR")
best_automl_model <- auto_both@leader
# best_stacked_model <- h2o.get_best_model(auto_both,"stackedensemble",criterion ="AUCPR")

h2o.saveModel(best_gbm_model,"C:/TER2/TER/auto_ml_both_model/best")
h2o.saveModel(best_glm_model,"C:/TER2/TER/auto_ml_both_model/best")
h2o.saveModel(best_drf_model,"C:/TER2/TER/auto_ml_both_model/best")
# h2o.saveModel(h2o.getModel("DRF_1_AutoML_1_20250310_02332"),path = "C:/TER2/TER/auto_ml_both_model/best")

# Best model ID DRF_1_AutoML_1_20250310_02332 

```

```{r}
best_automl_model <- h2o.loadModel("C:/TER2/TER/auto_ml_both_model/best/DRF_1_AutoML_1_20250310_02332 ")

best_glm_model <- h2o.loadModel("C:/TER2/TER/auto_ml_both_model/best/GLM_1_AutoML_1_20250310_02332 ")

best_gbm_model <- h2o.loadModel("C:/TER2/TER/auto_ml_both_model/best/GBM_grid_1_AutoML_1_20250310_02332_model_8 ")

best_xrt_model <- h2o.loadModel("C:/TER2/TER/auto_ml_both_model/XRT_1_AutoML_1_20250310_02332")
```

```{r}

stack_model <- h2o.stackedEnsemble(
  x=x,
  y=y,
  training_frame = Train_both,
  validation_frame = test,
  seed = 123,
  metalearner_nfolds = 9,
  # metalearner_algorithm = "drf",
#   metalearner_params = list(
#   ntrees = 40,
#   score_tree_interval = 5,
#   distribution = "bernoulli",
#   stopping_metric = "AUCPR",
#   stopping_tolerance = 0.002416721
#   # calibrate_model = TRUE,
#   # calibration_method = "PlattScaling"
# ),
  base_models = c(best_gbm_model,best_automl_model)
)
pred_leader <- h2o.predict(best_automl_model,test)




stacked_perf <- h2o.performance(stack_model,test)
best_gbm_perf_automl <- h2o.performance(best_gbm_model,test)
best_glm_perf_automl <- h2o.performance(best_glm_model,test)
best_drf_perf_automl <- h2o.performance(best_drf_model,test)
best_xrt_perf_automl <- h2o.performance(best_xrt_model,test)
leader_perf_automl <- h2o.performance(best_automl_model,test)


best_automl_model@parameters

# h2o.saveModel(stack_model,"C:/TER2/TER/auto_ml_both_model/best")

# rf <- h2o.randomForest(
#   x=x,
#   y=y,
#   ntrees = 40,
#   training_frame = Train_both,
#   validation_frame = test,
#   score_tree_interval = 5,
#   stopping_metric = "AUCPR",
#   stopping_tolerance = 0.002416721,
#   seed=125,
#   nfolds = 5,
#   calibration_frame = calib,
#   # distribution = "bernoulli",
#   calibrate_model = TRUE,
#   calibration_method = "PlattScaling"
#   
# )

# Lift(stack_model)
# draw_pr(h2o.performance(rf,test),"","",x=0.9)
# 
# matrice_conf(h2o.performance(rf,test),"","")
```

```{r}
#leader_perf_automl@metrics$thresholds_and_metric_scores |> select(threshold,absolute_mcc,tpr,tnr,fpr,fnr,specificity,f1,f0point5,recall) |>  View()
# Example usage





```

### Best model

```{r}



A <- h2o.learning_curve_plot(best_automl_model,"aucpr")+
  labs(x="Nombres d'arbres",
       y="PRAUC",
       title= "Courbe d'apprentissage",
       subtitle = "Model:RF "
       )

B <- h2o.learning_curve_plot(best_automl_model,"auc")+
  labs(x="Nombres d'arbres",
       # y=,
       title= "",
       subtitle = " "
       )

# C <- h2o.learning_curve_plot(best_automl_model,"logloss")+
#   labs(x="Nombres d'arbres",
#        # y=,
#        title= "",
#        subtitle = " "
#        )
# plot_grid(A,B,nrow = 2)
grid.arrange(A,B,nrow=2)
```

#### Matrice de confusion

```{r}
matrice_conf(leader_perf_automl,"RF","C'est le meilleur modèle GBM parmit celle généré par AutoML.h2o")
```

```{r}
Importance_plot(best_automl_model,test)
```

#### Courbe Lift

```{r}
Lift(best_automl_model)
```

#### Courbe precision recall

```{r}
draw_pr(leader_perf_automl,"Leader AutoML","Echantillonage :Over + under Sampling")
```

#### Courbe Roc

```{r}
Roc(leader_perf_automl)
```

#### shapley

```{r}
h2o.shap_summary_plot(best_automl_model,test,top_n_features=10,sample_size =4000 ) |> ggplotly()

# 
# pred_contrib_leader <- h2o.predict_contributions(best_automl_model,
#                                               test,
#                                               top_n = 10,
#                                               compare_abs = TRUE)
# # 
# 
# ID <- pred_contrib_leader |>  h2o.getId() 
# 
# h2o.save_frame(pred_contrib_leader,"C:/TER2/TER/auto_ml_both_model")

pred_contrib_leader <- h2o.load_frame("contributions__8884_DRF_1_AutoML_1_20250310_02332_on_RTMP_sid_87e9_11","C:/TER2/TER/auto_ml_both_model")
```

```{r}
pred_contrib_leader <- h2o.predict_contributions(best_gbm_model,calib)

# Conversion en format long pour ggplot2
shap_long <- pred_contrib_leader %>% as.data.frame() |> 
  pivot_longer(cols = -BiasTerm, names_to = "Variables", values_to = "Valeur_shap")


shap_stats <- shap_long %>%
  group_by(Variables) %>%
  summarise(Mean_SHAP = mean(abs(Valeur_shap)), Variance_SHAP = var(Valeur_shap))


# Aperçu des données transformées
# head(shap_long)

B <- ggplot(shap_long, aes(x = reorder(Variables, abs(Valeur_shap), FUN = median), y = Valeur_shap, fill = Variables)) +
  geom_boxplot(alpha = 0.7) +
  coord_flip() +
  theme_minimal() +
  labs(title = "Distribution des valeurs SHAP par variable", x = "Feature", y = "Valeur SHAP") +
  theme(legend.position = "none")



A <- ggplot(shap_stats, aes(x = Mean_SHAP, y = Variance_SHAP, label = Variables)) +
  geom_point(color = "blue") +
  geom_text(vjust = 1.5) +
  theme_minimal() +
  labs(title = "Relation entre Moyenne et Variance des Valeurs SHAP",
       x = "Moyenne des valeurs SHAP (Importance globale)",
       y = "Variance des valeurs SHAP (Stabilité de l'impact)")


B+A

```

```{r}
performance_models <- performance_all_model(leader_perf_automl, threshold = 0.4500000, Nom = "leader")

performance_models

```

```{r}
```

#### Gradient Boosting Model AutoML

```{r}


A <- h2o.learning_curve_plot(best_gbm_model,"aucpr")+
  labs(x="Nombres d'arbres",
       y="PRAUC",
       title= "Courbe d'apprentissage",
       subtitle = "Model:Gradient Boosting "
       )

B <- h2o.learning_curve_plot(best_gbm_model,"auc")+
  labs(x="Nombres d'arbres",
       # y=,
       title= "",
       subtitle = " "
       )

# plot_grid(A,B,nrow = 2)
grid.arrange(A,B,nrow=2)
```

```{r}
matrice_conf(best_gbm_perf_automl,"Gradient Boosting","C'est le meilleur modèle GBM parmit celle généré par AutoML.h2o")
```

```{r}
Importance_plot(best_gbm_model,test)
```

#### Courbe Lift

-   **Si le Lift du 1er décile est très haut (ex : 30x ou plus)**, le modèle est **très efficace pour classer les fraudes en haut**.

<!-- -->

-   **Si le Lift est faible (proche de 1 partout)**, alors **le modèle ne fait pas mieux qu’un tri aléatoire**.

<!-- -->

-   **Si le Response Rate dans les premiers déciles est élevé**, le modèle détecte bien les fraudes en priorité.

```{r}
Lift(best_gbm_perf_automl)
h2o.gainsLift(best_gbm_perf_automl) |> select(cumulative_data_fraction,lift,response_rate)



```

```{r}
draw_pr(best_gbm_perf_automl,"Model:GBM","AutoMl")
```

```{r}
# Extraire les valeurs de Sensitivité et Spécificité
roc_gbm_data <- data.frame(
  Sensitivite = h2o.tpr(best_gbm_perf_automl)$tpr,
  Specificite = h2o.fpr(best_gbm_perf_automl)$fpr
)

# Tracer la courbe ROC
ggplot(roc_gbm_data, aes(x = Specificite, y = Sensitivite)) +
  geom_line(color="black",linewidth=1) +
  labs(x = "1-Specificité", y = "Sensitivité", title = "Courbe ROC")+
  geom_abline(intercept = 0,color="skyblue",linewidth=0.7)+
  si_style()

```

#### Permutations importance

**L'importance de la variable de permutation** est obtenue en mesurant [la distance entre les erreurs de prédiction avant et après la permutation]{.underline} d’une caractéristique ; Une seule fonction à la fois est permutée.

```{r}

```

I.  Interprétation du modèle

```{r}
# shap <- 
h2o.shap_summary_plot(best_gbm_model,test) |> plotly::ggplotly()
# gbm_pred_contrib <- h2o.predict_contributions(best_gbm_model,
#                                               test,
#                                               top_n = 10,
#                                               compare_abs = TRUE)
# 
# h2o.save_frame(gbm_pred_contrib,"gbm_pred_contrib",force=TRUE)
# h2o.getId(gbm_pred_contrib)
gbm_pred_contrib <- h2o.load_frame("contributions__b166_GBM_grid_1_AutoML_1_20250310_02332_model_8_on_RTMP_sid_87e9_11","C:/TER2/TER/auto_ml_both_model")
```

#### LIME

```{r}

explicateur <- lime::lime(x=Train_both |>  as.data.frame(),model=best_gbm_model)

explications <- lime::explain(x = test |> as.data.frame(), explainer = explicateur, n_labels = 1, n_features = 5)


lime::plot_features(explications)


```

#### **Amplitudes des coefficients normalisés**

Ce graphique représente la relation entre une caractéristique spécifique et la variable de réponse. Les coefficients peuvent être positifs (orange) ou négatifs (bleu). Un coefficient positif indique une relation positive entre la caractéristique et la réponse, où une augmentation de la caractéristique correspond à une augmentation de la réponse, tandis qu’un coefficient négatif représente une relation négative entre la caractéristique et la réponse où une augmentation de la caractéristique correspond à une diminution de la réponse (ou vice versa).

```{r}
h2o.std_coef_plot(best_glm_model)
```

-   Les variables **V14 et V1**2 exercent ***l’influence négative la plus forte sur la prédiction*** avec des coefficients maximaux. Plus ces variables augmente plus le modèle a tendance a `prédire une transaction légitime et inversement elle prédit une transaction frauduleuses`

-   Les variables **V5,V11 et V7 r**eprésente les variable ayant une `l’influence positive` avec un coefficient positive.

-   Plus la valeur est grande plus la transactions est susceptible d'être une fraude

-   La majorité des variables (**V14, V12, V16, V3, V10, V17, Time, V25**) ont un impact négatif sur le résultat, tandis que seulement trois variables (**V5, V11, V7**) contribuent positivement.

```{r}



lb <- auto@leaderboard
auto@leader
auto@leaderboardm

model_ids <- as.data.frame(lb$model_id)

se <- h2o.getModel(grep("StackedEnsemble_AllModels",model_ids,value = TRUE)[1])




# h2o.saveModel(se,"model_h2o_se")
seb <- h2o.getModel(model_id="StackedEnsemble_BestOfFamily_1_AutoML_1_20250308_112044")
metaleaner <- h2o.getModel(se@model$metalearner$name)

# h2o.saveModel(seb,"stacked_ensemble_best_of_family")
gbm_id <- model_ids |> filter(grepl("^GBM",model_id))
# xrt_ids <- model_ids[grepl("^GBM", model_ids)]

grep("GBM",model_ids,value=TRUE)[1]
xrt <- h2o.getModel(model_id = "XRT_1_AutoML_1_20250308_112044")
DRF <- h2o.getModel(model_id = "DRF_1_AutoML_1_20250308_112044")
GLM <- h2o.getModel(model_id = "GLM_1_AutoML_1_20250308_112044")
DeepLearning <- h2o.getModel(model_id = "DeepLearning_1_AutoML_1_20250308_112044")

gbm_model <- list()
for(i in 1:nrow(gbm_id)){
  print(i)
gbm_model[[i]] <- h2o.getModel(model_id = gbm_id[i,])
}



# models_to_save <- list(
#   "GBM" = gbm,
#   "XRT" = xrt,
#   "DRF" = DRF,
#   "GLM" = GLM,
#   "DeepLearning" = DeepLearning
# )
# 
# # Boucle pour sauvegarder chaque modèle
# for (model_name in names(models_to_save)) {
#   model <- models_to_save[[model_name]]
#   h2o.saveModel(model, path = paste0(model_name, "_h2o_autoML"))
#   print(paste("Modèle", model_name, "sauvegardé."))
# }


```

```{r}

names <- se@model$cross_validation_metrics_summary |> row.names()
Summary <- cbind(Metrics=names,se@model$cross_validation_metrics_summary ) t(Summary)

Summary |> gt() |> 
  # tab_caption(caption = "nkjdsnj") |> 
  tab_header(title="Résumé des differentes metriques") |> 
  tab_style(
    style=list(
      cell_fill(color="#FFFACD")),
    locations=cells_body(columns = 1)
  ) |> 
  tab_style(
    style=list(
      cell_fill(color="Lightskyblue")
    ),
    locations = cells_body(columns = 2))
```

```{r}
#Prediction avec le model leader
predictions <- h2o.predict(auto@leader,test)
# performa,ce dmodel
perf_leader <- h2o.performance(auto@leader,test,valid = TRUE)
```

```{r}
# 
# tracer_courbes_roc_h2o <- function(modeles, noms_modeles, donnees_test) {
#   # ____________________________________________________________
#   # Trace les courbes ROC pour plusieurs modèles H2O dans un seul graphique.
#   # 
#   # Args:
#   #   modeles: Une liste de modèles H2O.
#   #   noms_modeles: Un vecteur de chaînes de caractères contenant les noms des modèles.
#   #   donnees_test: Un H2OFrame contenant les données de test.
#   # 
#   # Returns:
#   #   Un graphique ggplot2 contenant les courbes ROC pour chaque modèle.
#   # # _________________________________________________________
# 
#   # Créer un dataframe pour stocker les résultats
#   roc_data <- data.frame()
# 
#   # Boucle sur les modèles
#   for (i in 1:6) {
#     modele <- modeles[[i]]
#     nom_modele <- noms_modeles[i]
# 
#     # Obtenir l'objet de performance H2O
#     performance <- h2o.performance(modele, newdata = donnees_test)
# 
#     # Extraire les spécificités et les sensibilités
#     fpr <- h2o.fpr(performance)
#     tpr <- h2o.tpr(performance)
# 
#     # Ajouter les résultats au dataframe
#     roc_data <- rbind(roc_data, data.frame(FPR = fpr, TPR = tpr, Model = nom_modele))
#   }
# 
#   # Tracer les courbes ROC avec ggplot2
#   ggplot(roc_data, aes(x = FPR, y = TPR, color = Model)) +
#     geom_line() +
#     geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray") +
#     labs(
#       title = "Courbes ROC pour différents modèles H2O",
#       x = "Taux de faux positifs (1 - Spécificité)",
#       y = "Taux de vrais positifs (Sensibilité)"
#     ) +
#     theme_minimal()
# }
# 



```

```{r}

# MetricAutoMl_data <- data.frame(
#   row.names = c("GBM","XRT","GLM","DeepLearning","DRF"),
#   Specificity=c(),
#   Sensitivity =c(),
#   Score_F1=c(),
#   
# )

model_leader <-auto@leader
model_leader@parameters
# h2o.saveModel(best_gbm_model,"best_model_gbm_from_auto_ml")
best_performance_gbm <- h2o.performance(best_gbm_model,test)
Test_Calib <- h2o.performance(best_gbm_model,calib)


```

```{r}
matrice_conf(best_performance_gbm,"GBM","Model:Best GBM model from AutoML")
matrice_conf(Test_Calib,"GBM,2éme test d'efficacité","Données:Calibrage") 
```

```{r}

A <- h2o.learning_curve_plot(best_gbm_model,"aucpr")+
  labs(
  title = "Courbe d'apprentissage ",
  subtitle = "Gradient Boosting  (Model)",
  x="Arbres",
  y="Auc Précision",
  caption = "Data:Vars OverSampling"
)
B <- h2o.learning_curve_plot(best_gbm_model,"auc")+
  labs(
  title = "Courbe d'apprentissage ",
  subtitle = "Gradient Boosting (Model)",
  x="Arbres",
  y="AUC",
  caption = "Data:Vars OverSampling"
)

# plot_grid(A,B,nrow = 1,scale = 1)

gridExtra::grid.arrange(A,B,nrow=2)
```

```{r}
h2o.varimp_plot(best_gbm_model)

```

```{r}
best_gbm_model@model$variable_importances |> 
  ggplot(aes(x=reorder(variable, - scaled_importance), y=scaled_importance, fill=scaled_importance)) +
  geom_col() +
  scale_fill_viridis_c(option = "A") +  # Dégradé thermique (Viridis)
  labs(x="Variable",
       y="Features Importances",
       title="Variables importantes",
       fill="Importances") +
  bbc_style()+
  theme(legend.text = element_text(size=12),
        legend.title = element_text(size=15,family = "serif",face="bold.italic",color = "purple"))+
  theme_pubclean()+
  theme(legend.title = element_text(size=15,family = "serif",face="bold.italic",color = "darkred"),
        plot.title = element_text(color="darkred",face="bold.italic"),
        legend.position = "right")+
   coord_flip() 

# Installer devtools si ce n'est pas déjà fait
# install.packages("devtools")


# # Finalisons le graphique avec le logo et les dimensions spécifiées
# bbplot::finalise_plot(
#   plot_name = plt,
#   source_name = "Source: Votre Source",
#   # save_filepath = "chemin/vers/votre_graphique.png",
#   width_pixels = 840,
#   height_pixels = 180
#   # logo_image_path = "chemin/vers/logo.png"
# )


```

Les ***V10,V12,V14 et V17** sont les variables que ce modèle estime comme étant les plus **influents*** dans le sens où ces variables sont très discriminantes pour la prédiction des transactions frauduleuses . Nous allons **analyser** en détails leurs contributions dans la **prédiction** des ***transactions frauduleuses***

```{r}
h2o.shap_explain_row_plot(
  best_gbm_model,
  test
)
```

```{r}
# permutations_plot <- h2o.permutation_importance(
#   best_gbm_model,
#   test,
#   metric = "AUTO",
#   n_repeats = 100,
#   seed=123
#   # n_samples = 20
#   
# )
```

#### Synthèse

```{r}
h2o.varimp_heatmap(auto) |> ggplotly()
```

```{r}
library(cowplot)
lift <- Lift(auto@leader)
lean_curve <- h2o.learning_curve_plot(auto@leader)
mat_conf <- matrice_conf(perf_leader,"","")
Var_imp_leader <- h2o.varimp(auto@leader)
# mat_conf_grob <- as_grob(mat_conf)
# plot_grid(pr,lift,lean_curve)
draw_pr(perf_leader,"","")
lean_curve
lift
mat_conf
# pr
h2o.varimp_plot(auto@leader)
```

```{r}
perf <- h2o.performance(gbm,test)
draw_pr(perf,"","")
matrice_conf(perf,"","")
Lift(gbm)
h2o.learning_curve_plot(gbm,"auc")
```

```{r}

gbm_model_over <- h2o.gbm(
  x=x,
  y=y,
  training_frame = Train_over,
  validation_frame = test,
  # nfolds = 5,
  # ntrees = 30,
  # seed=123,
  max_depth =13,
  # min_rows = 20,
  # # fold_assignment = "Random",
  learn_rate = 0.1
  # # weights_column = "weight",
  # sample_rate = 0.75,
  # # keep_cross_validation_predictions = TRUE,
  # col_sample_rate = 0.75,
  # 
  # calibrate_model = TRUE,
  # calibration_frame = calib,
  # calibration_method = "PlattScaling" #PlattScaling
  
)
perf_gbm_over <- h2o.performance(gbm_model_over,test,valid = TRUE)
pred_gbm_over <- h2o.predict(gbm_model_over,test)
perf_gbm_over
```

#### Matrice de confusion

```{r}
matrice_conf(perf_gbm_over,"Gradient Boosting Model","Echantillonge:OverSampling")
```

```{r}
#| message: false
#| warning: false
library(ggthemes)
 h2o.learning_curve_plot(gbm_model_over,"aucpr")+labs(
  title = "Courbe d'apprentissage ",
  subtitle = "Gradient Boosting (Model)",
  x="Arbres",
  y="aucpr",
  caption = "Data:Vars OverSampling")
# )+geom_jitter(shape=21,size=0.5)+
  # # ggthemes::theme_fivethirtyeight(base_size = 9,
  # #                                  base_family = "serif")+
  #  # si_style()
  # theme(text = element_text(
  #   colour = "grey30"
  # ),plot.title.position = "plot",
  # plot.caption.position = "plot"
  # )+scale_color_manual(values=c("#E69F00", "#009E73", "#0072B2","#CC79A7"))
```

```{r}

draw_pr(perf = perf_gbm_over,"Model: GBM","Echantillonage:OverSampling",x=0.8)
```

```{r}
Lift(gbm_model_over)
```

```{r}

gbm_model_both <- h2o.gbm(
  x=x,
  y=y,
  training_frame = Train_both,
  validation_frame = test,
  nfolds = 5,
  ntrees = 150,
  seed=123,
  max_depth =5,
  min_rows = 10,
  # fold_assignment = "Random",
  learn_rate = 0.08 ,
  # weights_column = "weight",
  sample_rate = 0.85,
  # keep_cross_validation_predictions = TRUE,
  col_sample_rate = 0.75,
  calibrate_model = TRUE,
  calibration_frame = calib,
  calibration_method = "PlattScaling" #PlattScaling
  
)
perf_gbm_over <- h2o.performance(gbm_model_over,test,valid = TRUE)
pred_gbm_over <- h2o.predict(gbm_model_over,test)
perf_gbm_over
```

#### Arbre de decisions

```{r}
rpart_model <- h2o.decision_tree(
  x=x,
  y=y,
  training_frame = train,
  seed=123,
  max_depth = 6

)

# thematic::okabe_ito(4)

rpart_perf <- h2o.performance(rpart_model,test)
rpart_perf
```

```{r}
h2o.gains_lift_plot(rpart_perf)

```

#### Xgboost

```{r}


```

```{r}

glm_model <- h2o.glm(
  x = x,
  y = y,
  training_frame = train,
  validation_frame = test,
  family = "binomial",
  lambda_search = TRUE  # Recherche de régularisation (LASSO/Ridge)
)

```

```{r}
# Les deux commandes suivantes suppriment tous les packages H2O précédemment 

h2o.xgboost.available()

```
